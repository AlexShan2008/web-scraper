# Web Scraper Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# MAIN WEB SCRAPER SETTINGS
# =============================================================================

# Target URL to scrape
TARGET_URL=https://httpbin.org/html

# CSS Selectors for data extraction (JSON format)
# Format: {"field_name": "css_selector"}
SELECTORS={"title": "h1", "description": "meta[name=\"description\"]", "links": "a[href]"}

# Scraping behavior settings
DELAY_MIN=2
DELAY_MAX=4
TIMEOUT=30
MAX_RETRIES=3
RESPECT_ROBOTS=true
USE_SELENIUM=false

# Output settings
OUTPUT_JSON=scraped_data.json
OUTPUT_CSV=scraped_data.csv

# User agent settings (optional)
# If not set, will use fake-useragent library or default
CUSTOM_USER_AGENT=

# Proxy settings (optional)
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=https://proxy.example.com:8080

# Selenium settings (if using Selenium)
CHROME_DRIVER_PATH=
SELENIUM_HEADLESS=true
SELENIUM_WINDOW_SIZE=1920,1080

# Logging settings
LOG_LEVEL=INFO
LOG_FILE=scraper.log

# =============================================================================
# WIKIPEDIA TABLE SCRAPER SETTINGS
# =============================================================================

# Wikipedia URL to scrape
WIKI_URL=https://en.wikipedia.org/wiki/Cloud-computing_comparison

# Table index to scrape (0 = first table, 1 = second table, etc.)
WIKI_TABLE_INDEX=0

# Output file for Wikipedia table data
WIKI_OUTPUT_FILE=wikipedia_table_data.csv 